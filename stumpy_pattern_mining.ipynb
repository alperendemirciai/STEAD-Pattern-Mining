{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd10111",
   "metadata": {},
   "source": [
    "# Pattern Mining Phase: Matrix Profile Analysis\n",
    "\n",
    "To validate the approximate motifs detected by SAX, a second high-precision pattern mining stage was conducted using the **Matrix Profile** method, implemented via the `stumpy` Python library. Unlike SAX, which relies on discretization, the Matrix Profile computes the exact Euclidean distances between all subsequences, offering a parameter-free method to identify motifs (repeating patterns) and discords (anomalies).\n",
    "\n",
    "### Methodology\n",
    "The Matrix Profile was computed for the Earthquake Time Series (E, N, and V channels) to locate the most conserved waveform shapes.\n",
    "\n",
    "* **Algorithm:** We utilized `stumpy.stump`, a highly parallelized implementation of the exact motif discovery algorithm.\n",
    "* **Window Size ($m$):** A window size of $m=1000,$ (approx. 10 second) was selected, consistent with the stable motif duration identified in the SAX analysis.\n",
    "* **Metric:** **Z-normalized Euclidean Distance**. This normalization is critical for seismic analysis as it focuses on waveform *shape* rather than absolute *amplitude*, allowing the detection of repeating scattering patterns even as the earthquake signal attenuates over time.\n",
    "\n",
    "\n",
    "\n",
    "### Analytical Objectives\n",
    "The Matrix Profile vector $P$ was analyzed to extract two key physical features:\n",
    "\n",
    "1.  **Motif Discovery (Global Minima):**\n",
    "    The indices of the minimum values in $P$ correspond to the **Top-1 Motif**—the pair of subsequences with the highest similarity. This identifies the \"signature\" waveform of the site's crustal response.\n",
    "\n",
    "2.  **Regime Change Detection (Semantic Segmentation):**\n",
    "    By analyzing transitions in the Matrix Profile values, we identified boundaries between different physical regimes (e.g., the transition from the chaotic P-onset to the rhythmic, repeating Coda phase).\n",
    "\n",
    "### Comparison with SAX Results\n",
    "This stage serves as a verification step. While SAX provides a global statistical view of symbol distribution, `stumpy` provides exact localization.\n",
    "* **Expectation:** If the SAX \"P-coda motif\" is real, the Matrix Profile should show a distinct \"valley\" (low distance values) in the region between P and S arrivals, indicating high self-similarity.\n",
    "* **Discords:** High values in the Matrix Profile will highlight non-repeating transients, expected to correspond to the unique impulsive onsets of the P and S phases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba11081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29871, 3, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "signal_data = np.load(\"signal_data/processed_seismic_data.npy\")\n",
    "\n",
    "print(signal_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92de93dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29871, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_name</th>\n",
       "      <th>network_code</th>\n",
       "      <th>receiver_code</th>\n",
       "      <th>receiver_type</th>\n",
       "      <th>source_origin_time</th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>receiver_latitude</th>\n",
       "      <th>receiver_longitude</th>\n",
       "      <th>receiver_elevation_m</th>\n",
       "      <th>p_arrival_sample</th>\n",
       "      <th>...</th>\n",
       "      <th>source_magnitude</th>\n",
       "      <th>source_magnitude_type</th>\n",
       "      <th>source_distance_km</th>\n",
       "      <th>back_azimuth_deg</th>\n",
       "      <th>coda_end_sample</th>\n",
       "      <th>id</th>\n",
       "      <th>norm_s_arrival_sample</th>\n",
       "      <th>snr_db_E</th>\n",
       "      <th>snr_db_N</th>\n",
       "      <th>snr_db_V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109C.TA_20061103155652_EV</td>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>BH</td>\n",
       "      <td>2006-11-03 15:56:42.73</td>\n",
       "      <td>2006-11-03 15:56:53.610000</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>101.34</td>\n",
       "      <td>281.7</td>\n",
       "      <td>5508</td>\n",
       "      <td>235427</td>\n",
       "      <td>236</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>61.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109C.TA_20061129211102_EV</td>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>BH</td>\n",
       "      <td>2006-11-29 21:10:55.02</td>\n",
       "      <td>2006-11-29 21:11:03.890000</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>ml</td>\n",
       "      <td>108.03</td>\n",
       "      <td>273.8</td>\n",
       "      <td>3199</td>\n",
       "      <td>235432</td>\n",
       "      <td>558</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>56.099998</td>\n",
       "      <td>43.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109C.TA_20061129221547_EV</td>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>BH</td>\n",
       "      <td>2006-11-29 22:15:38.65</td>\n",
       "      <td>2006-11-29 22:15:48.630000</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>ml</td>\n",
       "      <td>106.69</td>\n",
       "      <td>273.7</td>\n",
       "      <td>5252</td>\n",
       "      <td>235434</td>\n",
       "      <td>283</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>39.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109C.TA_20070209033349_EV</td>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>BH</td>\n",
       "      <td>2007-02-09 03:33:42.80</td>\n",
       "      <td>2007-02-09 03:33:50.600000</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>ml</td>\n",
       "      <td>98.93</td>\n",
       "      <td>246.8</td>\n",
       "      <td>2866</td>\n",
       "      <td>235437</td>\n",
       "      <td>580</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>68.199997</td>\n",
       "      <td>58.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109C.TA_20070415225732_EV</td>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>BH</td>\n",
       "      <td>2007-04-15 22:57:25.78</td>\n",
       "      <td>2007-04-15 22:57:33.940000</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>ml</td>\n",
       "      <td>99.46</td>\n",
       "      <td>280.3</td>\n",
       "      <td>5848</td>\n",
       "      <td>235441</td>\n",
       "      <td>240</td>\n",
       "      <td>60.099998</td>\n",
       "      <td>64.800003</td>\n",
       "      <td>53.400002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  trace_name network_code receiver_code receiver_type  \\\n",
       "0  109C.TA_20061103155652_EV           TA          109C            BH   \n",
       "1  109C.TA_20061129211102_EV           TA          109C            BH   \n",
       "2  109C.TA_20061129221547_EV           TA          109C            BH   \n",
       "3  109C.TA_20070209033349_EV           TA          109C            BH   \n",
       "4  109C.TA_20070415225732_EV           TA          109C            BH   \n",
       "\n",
       "       source_origin_time            trace_start_time  receiver_latitude  \\\n",
       "0  2006-11-03 15:56:42.73  2006-11-03 15:56:53.610000            32.8889   \n",
       "1  2006-11-29 21:10:55.02  2006-11-29 21:11:03.890000            32.8889   \n",
       "2  2006-11-29 22:15:38.65  2006-11-29 22:15:48.630000            32.8889   \n",
       "3  2007-02-09 03:33:42.80  2007-02-09 03:33:50.600000            32.8889   \n",
       "4  2007-04-15 22:57:25.78  2007-04-15 22:57:33.940000            32.8889   \n",
       "\n",
       "   receiver_longitude  receiver_elevation_m  p_arrival_sample  ...  \\\n",
       "0           -117.1051                 150.0             600.0  ...   \n",
       "1           -117.1051                 150.0             900.0  ...   \n",
       "2           -117.1051                 150.0             800.0  ...   \n",
       "3           -117.1051                 150.0             900.0  ...   \n",
       "4           -117.1051                 150.0             900.0  ...   \n",
       "\n",
       "  source_magnitude  source_magnitude_type  source_distance_km  \\\n",
       "0              4.3                     mb              101.34   \n",
       "1              4.1                     ml              108.03   \n",
       "2              3.9                     ml              106.69   \n",
       "3              4.2                     ml               98.93   \n",
       "4              4.3                     ml               99.46   \n",
       "\n",
       "  back_azimuth_deg coda_end_sample      id  norm_s_arrival_sample   snr_db_E  \\\n",
       "0            281.7            5508  235427                    236  65.000000   \n",
       "1            273.8            3199  235432                    558  55.000000   \n",
       "2            273.7            5252  235434                    283  49.000000   \n",
       "3            246.8            2866  235437                    580  65.000000   \n",
       "4            280.3            5848  235441                    240  60.099998   \n",
       "\n",
       "    snr_db_N   snr_db_V  \n",
       "0  65.500000  61.400002  \n",
       "1  56.099998  43.200001  \n",
       "2  48.000000  39.200001  \n",
       "3  68.199997  58.700001  \n",
       "4  64.800003  53.400002  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"metadata/processed_metadata.csv\")\n",
    "\n",
    "print(metadata.shape)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5d4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trace_name', 'network_code', 'receiver_code', 'receiver_type',\n",
      "       'source_origin_time', 'trace_start_time', 'receiver_latitude',\n",
      "       'receiver_longitude', 'receiver_elevation_m', 'p_arrival_sample',\n",
      "       'p_status', 'p_travel_sec', 's_arrival_sample', 's_status', 'source_id',\n",
      "       'source_latitude', 'source_longitude', 'source_depth_km',\n",
      "       'source_magnitude', 'source_magnitude_type', 'source_distance_km',\n",
      "       'back_azimuth_deg', 'coda_end_sample', 'id', 'norm_s_arrival_sample',\n",
      "       'snr_db_E', 'snr_db_N', 'snr_db_V'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffafdcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=100\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=100: 100%|██████████| 29871/29871 [49:46<00:00, 10.00it/s]\n",
      "Elbow m=100: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: motif_results/m_100/clusters_m100.png\n",
      "Saved: motif_results/m_100/elbow_m100.png\n",
      "Motif extraction for m=100 complete.\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=200\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=200: 100%|██████████| 29871/29871 [39:55<00:00, 12.47it/s]\n",
      "Elbow m=200: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: motif_results/m_200/clusters_m200.png\n",
      "Saved: motif_results/m_200/elbow_m200.png\n",
      "Motif extraction for m=200 complete.\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=500\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=500: 100%|██████████| 29871/29871 [19:04<00:00, 26.10it/s]\n",
      "Elbow m=500: 100%|██████████| 8/8 [00:23<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: motif_results/m_500/clusters_m500.png\n",
      "Saved: motif_results/m_500/elbow_m500.png\n",
      "Motif extraction for m=500 complete.\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=1000\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=1000: 100%|██████████| 29871/29871 [01:49<00:00, 271.83it/s]\n",
      "Elbow m=1000: 100%|██████████| 8/8 [01:29<00:00, 11.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: motif_results/m_1000/clusters_m1000.png\n",
      "Saved: motif_results/m_1000/elbow_m1000.png\n",
      "Motif extraction for m=1000 complete.\n",
      "\n",
      "\n",
      "ALL MOTIF LENGTHS FINISHED SUCCESSFULLY ✔\n"
     ]
    }
   ],
   "source": [
    "import stumpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ================================================================\n",
    "# 0. Ensure output directory exists\n",
    "# ================================================================\n",
    "os.makedirs(\"motif_results\", exist_ok=True)\n",
    "\n",
    "# ================================================================\n",
    "# 1. PARAMETERS\n",
    "# ================================================================\n",
    "MOTIF_LENGTHS = [100, 200, 500, 1000]\n",
    "K_RANGE = range(2, 10)  # Elbow curve range\n",
    "N_CLUSTERS = 4          # Default cluster count\n",
    "N_EXAMPLES = 10         # Motifs to plot per cluster\n",
    "\n",
    "# signal_data shape must be (N, 3, T)\n",
    "signal_data = signal_data.astype(np.float64)\n",
    "N, C, T = signal_data.shape\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 2. LOOP OVER MOTIF LENGTHS\n",
    "# ================================================================\n",
    "for m in MOTIF_LENGTHS:\n",
    "    print(f\"\\n===============================\")\n",
    "    print(f\"   PROCESSING MOTIF LENGTH m={m}\")\n",
    "    print(f\"===============================\\n\")\n",
    "\n",
    "    save_dir = f\"motif_results/m_{m}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # ================================================================\n",
    "    # 2A. Extract motifs for all signals using mstump\n",
    "    # ================================================================\n",
    "    motif_shapes = []      # will be (N, 3, m)\n",
    "    motif_dists = []\n",
    "\n",
    "    for i in tqdm(range(N), desc=f\"Motifs m={m}\"):\n",
    "        signal = signal_data[i]\n",
    "\n",
    "        # compute multidimensional matrix profile\n",
    "        mp, _ = stumpy.mstump(signal, m)\n",
    "        \n",
    "        motif_idx = np.argmin(mp[0])\n",
    "        start, end = motif_idx, motif_idx + m\n",
    "        \n",
    "        motif_segment = signal[:, start:end]   # (3, m)\n",
    "        motif_shapes.append(motif_segment)\n",
    "        motif_dists.append(mp[0, motif_idx])\n",
    "\n",
    "    motif_shapes = np.array(motif_shapes)\n",
    "    motifs_flat = motif_shapes.reshape(N, C * m)\n",
    "\n",
    "    # Save motifs in case needed later\n",
    "    np.save(f\"{save_dir}/motifs.npy\", motif_shapes)\n",
    "    np.save(f\"{save_dir}/motif_distances.npy\", motif_dists)\n",
    "\n",
    "\n",
    "    # ================================================================\n",
    "    # 2B. K-Means ELBOW CURVE\n",
    "    # ================================================================\n",
    "    sse = []\n",
    "    for k in tqdm(K_RANGE, desc=f\"Elbow m={m}\"):\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        km.fit(motifs_flat)\n",
    "        sse.append(km.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(K_RANGE, sse, marker=\"o\")\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"SSE (Inertia)\")\n",
    "    plt.title(f\"Elbow Curve for m={m}\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/elbow_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # ================================================================\n",
    "    # 2C. Cluster with N_CLUSTERS and plot centroids\n",
    "    # ================================================================\n",
    "    kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "    labels = kmeans.fit_predict(motifs_flat)\n",
    "\n",
    "    np.save(f\"{save_dir}/labels.npy\", labels)\n",
    "\n",
    "    fig, axes = plt.subplots(C, N_CLUSTERS, figsize=(5*N_CLUSTERS, 10))\n",
    "\n",
    "    if C == 1:  # fix plot layout for single channel case\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for cluster_id in range(N_CLUSTERS):\n",
    "        centroid = kmeans.cluster_centers_[cluster_id].reshape(C, m)\n",
    "        cluster_idxs = np.where(labels == cluster_id)[0]\n",
    "\n",
    "        for ch in range(C):\n",
    "            ax = axes[ch, cluster_id]\n",
    "            ax.plot(centroid[ch], linewidth=3, label=\"Centroid\")\n",
    "\n",
    "            # plot examples\n",
    "            sample_idxs = (\n",
    "                np.random.choice(cluster_idxs, N_EXAMPLES, replace=False)\n",
    "                if len(cluster_idxs) > N_EXAMPLES else cluster_idxs\n",
    "            )\n",
    "\n",
    "            for idx in sample_idxs:\n",
    "                ax.plot(motif_shapes[idx][ch], alpha=0.4)\n",
    "\n",
    "            ax.set_title(f\"Cluster {cluster_id} — Channel {ch}\")\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(\"Amp\")\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/clusters_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {save_dir}/clusters_m{m}.png\")\n",
    "    print(f\"Saved: {save_dir}/elbow_m{m}.png\")\n",
    "    print(f\"Motif extraction for m={m} complete.\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nALL MOTIF LENGTHS FINISHED SUCCESSFULLY ✔\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b88935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=100\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=100: 100%|██████████| 29871/29871 [49:29<00:00, 10.06it/s]\n",
      "Auto-K m=100: 100%|██████████| 13/13 [03:22<00:00, 15.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTO SELECTED BEST k = 3\n",
      "✔ Saved centroid plots m=100\n",
      "✔ Auto-K = 3 finished\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=200\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=200: 100%|██████████| 29871/29871 [39:35<00:00, 12.58it/s]\n",
      "Auto-K m=200: 100%|██████████| 13/13 [04:07<00:00, 19.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTO SELECTED BEST k = 3\n",
      "✔ Saved centroid plots m=200\n",
      "✔ Auto-K = 3 finished\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=500\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=500: 100%|██████████| 29871/29871 [19:01<00:00, 26.17it/s]\n",
      "Auto-K m=500: 100%|██████████| 13/13 [07:02<00:00, 32.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTO SELECTED BEST k = 2\n",
      "✔ Saved centroid plots m=500\n",
      "✔ Auto-K = 2 finished\n",
      "\n",
      "\n",
      "===============================\n",
      "   PROCESSING MOTIF LENGTH m=1000\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motifs m=1000: 100%|██████████| 29871/29871 [01:49<00:00, 272.83it/s]\n",
      "Auto-K m=1000: 100%|██████████| 13/13 [12:36<00:00, 58.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTO SELECTED BEST k = 8\n",
      "✔ Saved centroid plots m=1000\n",
      "✔ Auto-K = 8 finished\n",
      "\n",
      "\n",
      "===============================\n",
      " ALL MOTIF LENGTHS FINISHED ✔ \n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "import stumpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ================================================================\n",
    "# 0. Ensure output directory exists\n",
    "# ================================================================\n",
    "os.makedirs(\"motif_results_adv\", exist_ok=True)\n",
    "\n",
    "# ================================================================\n",
    "# 1. PARAMETERS\n",
    "# ================================================================\n",
    "MOTIF_LENGTHS = [100, 200, 500, 1000]\n",
    "K_RANGE = range(2, 15)   # Auto K search range\n",
    "N_EXAMPLES = 10          # Motifs to plot per cluster\n",
    "\n",
    "signal_data = signal_data.astype(np.float64)\n",
    "N, C, T = signal_data.shape\n",
    "\n",
    "# ================================================================\n",
    "# 2. LOOP OVER MOTIF LENGTHS\n",
    "# ================================================================\n",
    "for m in MOTIF_LENGTHS:\n",
    "    print(f\"\\n===============================\")\n",
    "    print(f\"   PROCESSING MOTIF LENGTH m={m}\")\n",
    "    print(f\"===============================\\n\")\n",
    "\n",
    "    save_dir = f\"motif_results/m_{m}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # ================================================================\n",
    "    # 2A. EXTRACT MOTIFS USING MSTUMP\n",
    "    # ================================================================\n",
    "    motif_shapes = []\n",
    "    motif_dists = []\n",
    "\n",
    "    for i in tqdm(range(N), desc=f\"Motifs m={m}\"):\n",
    "        signal = signal_data[i]\n",
    "        mp, _ = stumpy.mstump(signal, m)\n",
    "\n",
    "        motif_idx = np.argmin(mp[0])\n",
    "        start, end = motif_idx, motif_idx + m\n",
    "\n",
    "        motif_segment = signal[:, start:end]\n",
    "        motif_shapes.append(motif_segment)\n",
    "        motif_dists.append(mp[0, motif_idx])\n",
    "\n",
    "    motif_shapes = np.array(motif_shapes)\n",
    "    motifs_flat = motif_shapes.reshape(N, C * m)\n",
    "\n",
    "    np.save(f\"{save_dir}/motifs.npy\", motif_shapes)\n",
    "    np.save(f\"{save_dir}/motif_distances.npy\", motif_dists)\n",
    "\n",
    "    # ================================================================\n",
    "    # 2B. AUTO-BEST-K SELECTION\n",
    "    # ================================================================\n",
    "    sse, sil_scores, ch_scores = [], [], []\n",
    "\n",
    "    for k in tqdm(K_RANGE, desc=f\"Auto-K m={m}\"):\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = km.fit_predict(motifs_flat)\n",
    "        sse.append(km.inertia_)\n",
    "\n",
    "        if len(set(labels)) > 1:\n",
    "            sil_scores.append(silhouette_score(motifs_flat, labels))\n",
    "            ch_scores.append(calinski_harabasz_score(motifs_flat, labels))\n",
    "        else:\n",
    "            sil_scores.append(-1)\n",
    "            ch_scores.append(-1)\n",
    "\n",
    "    # SELECT BEST K\n",
    "    best_k_sil = K_RANGE[np.argmax(sil_scores)]\n",
    "    best_k_ch = K_RANGE[np.argmax(ch_scores)]\n",
    "\n",
    "    # Combine votes → most robust\n",
    "    best_k = int(np.median([best_k_sil, best_k_ch]))\n",
    "    print(f\"\\nAUTO SELECTED BEST k = {best_k}\")\n",
    "\n",
    "    # Save elbow, silhouette, CH\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(K_RANGE, sse, marker=\"o\")\n",
    "    plt.title(f\"Elbow Curve (m={m})\")\n",
    "    plt.xlabel(\"k\"); plt.ylabel(\"SSE\")\n",
    "    plt.grid(); plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/elbow_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(K_RANGE, sil_scores, marker=\"o\")\n",
    "    plt.title(f\"Silhouette Scores (m={m})\")\n",
    "    plt.xlabel(\"k\"); plt.ylabel(\"Score\")\n",
    "    plt.grid(); plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/silhouette_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(K_RANGE, ch_scores, marker=\"o\")\n",
    "    plt.title(f\"Calinski-Harabasz Scores (m={m})\")\n",
    "    plt.xlabel(\"k\"); plt.ylabel(\"Score\")\n",
    "    plt.grid(); plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/ch_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ================================================================\n",
    "    # 2C. FINAL CLUSTERING WITH BEST K\n",
    "    # ================================================================\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(motifs_flat)\n",
    "\n",
    "    np.save(f\"{save_dir}/labels_kmeans.npy\", labels)\n",
    "\n",
    "    # ================================================================\n",
    "    # 2D. PCA 2D + 3D\n",
    "    # ================================================================\n",
    "    pca2 = PCA(n_components=2).fit_transform(motifs_flat)\n",
    "    pca3 = PCA(n_components=3).fit_transform(motifs_flat)\n",
    "\n",
    "    # 2D PCA\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for k in range(best_k):\n",
    "        idxs = np.where(labels == k)[0]\n",
    "        plt.scatter(pca2[idxs, 0], pca2[idxs, 1], label=f\"C{k}\", alpha=0.6)\n",
    "    plt.legend(); plt.title(f\"PCA 2D (m={m})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/pca2_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # 3D PCA\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for k in range(best_k):\n",
    "        idxs = np.where(labels == k)[0]\n",
    "        ax.scatter(pca3[idxs, 0], pca3[idxs, 1], pca3[idxs, 2], label=f\"C{k}\", alpha=0.5)\n",
    "    ax.set_title(f\"PCA 3D (m={m})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/pca3_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ================================================================\n",
    "    # 2E. HIERARCHICAL CLUSTERING (WARD)\n",
    "    # ================================================================\n",
    "    hier = AgglomerativeClustering(n_clusters=best_k, linkage=\"ward\")\n",
    "    labels_hier = hier.fit_predict(motifs_flat)\n",
    "    np.save(f\"{save_dir}/labels_hier.npy\", labels_hier)\n",
    "\n",
    "    # PCA 2D Visual Hierarchical\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for k in range(best_k):\n",
    "        idxs = np.where(labels_hier == k)[0]\n",
    "        plt.scatter(pca2[idxs, 0], pca2[idxs, 1], label=f\"H{k}\", alpha=0.6)\n",
    "    plt.legend(); plt.title(f\"Hierarchical PCA 2D (m={m})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/pca2_hier_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ================================================================\n",
    "    # 2F. PLOT CLUSTER CENTROIDS + EXAMPLES + COUNT\n",
    "    # ================================================================\n",
    "    fig, axes = plt.subplots(C, best_k, figsize=(6*best_k, 10))\n",
    "\n",
    "    if C == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "\n",
    "    for cluster_id in range(best_k):\n",
    "        centroid = kmeans.cluster_centers_[cluster_id].reshape(C, m)\n",
    "        cluster_idxs = np.where(labels == cluster_id)[0]\n",
    "        count = len(cluster_idxs)\n",
    "\n",
    "        for ch in range(C):\n",
    "            ax = axes[ch, cluster_id]\n",
    "\n",
    "            ax.plot(centroid[ch], linewidth=3, label=\"Centroid\", color=\"black\")\n",
    "\n",
    "            sample_idxs = (\n",
    "                np.random.choice(cluster_idxs, N_EXAMPLES, replace=False)\n",
    "                if count > N_EXAMPLES else cluster_idxs\n",
    "            )\n",
    "\n",
    "            for idx in sample_idxs:\n",
    "                ax.plot(motif_shapes[idx][ch], alpha=0.4)\n",
    "\n",
    "            ax.set_title(f\"Cluster {cluster_id} (n={count}) — Ch {ch}\")\n",
    "            ax.grid()\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/clusters_m{m}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✔ Saved centroid plots m={m}\")\n",
    "    print(f\"✔ Auto-K = {best_k} finished\\n\")\n",
    "\n",
    "print(\"\\n===============================\")\n",
    "print(\" ALL MOTIF LENGTHS FINISHED ✔ \")\n",
    "print(\"===============================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb05ac",
   "metadata": {},
   "source": [
    "# Code Explanation\n",
    "\n",
    "We applied multidimensional motif discovery and clustering to a dataset of **three-channel seismic signals** using motif lengths of 100, 200, 500, and 1000 time steps. The results reported here focus on the **1000-length motifs**, which produced the most stable and interpretable cluster structures.\n",
    "\n",
    "## 1. Motif Extraction\n",
    "\n",
    "Using **multidimensional matrix profiles (mstump)**, a representative motif was extracted from every signal across all three channels. These motifs served as compressed, shape-based descriptors of the dominant local pattern within each waveform.\n",
    "\n",
    "## 2. Automatic Cluster Selection\n",
    "\n",
    "For each motif length, we performed a systematic evaluation of candidate cluster numbers using:\n",
    "\n",
    "* **Within-cluster SSE (Elbow)**\n",
    "* **Silhouette Score**\n",
    "* **Calinski–Harabasz Index**\n",
    "\n",
    "The optimal number of clusters was determined by combining these metrics via a median-vote heuristic.\n",
    "For the 1000-step motifs, the best value converged to **k = 8 clusters**, indicating that the dataset contains approximately eight distinct characteristic waveform shapes.\n",
    "\n",
    "## 3. Cluster Structure and Centroid Patterns\n",
    "\n",
    "The cluster visualizations show each cluster's centroid (black curve) along with a large number of motif samples overlaid with transparency. Several strong trends emerged:\n",
    "\n",
    "### (a) Cluster Size Variation\n",
    "\n",
    "Clusters vary significantly in population:\n",
    "\n",
    "* Largest clusters contain **5000–6000 signals**\n",
    "* Smallest clusters contain **2500–3000 signals**\n",
    "\n",
    "This indicates that certain motif shapes occur far more frequently in the dataset.\n",
    "\n",
    "### (b) High Within-Cluster Agreement\n",
    "\n",
    "Many clusters display extremely tight overlay around the centroid, especially in:\n",
    "\n",
    "* **Channel 1** and **Channel 2**\n",
    "* The **mid-segment region** (≈ 300–800)\n",
    "\n",
    "This consistency suggests that the motifs capture a robust and repeated structural pattern in the underlying signals.\n",
    "\n",
    "### (c) Presence of Noise-Dominated Clusters\n",
    "\n",
    "A few clusters exhibit:\n",
    "\n",
    "* Larger variance envelopes\n",
    "* Weakly defined centroid features\n",
    "* High variability in amplitude\n",
    "\n",
    "These clusters likely correspond to **noisy signals**, **non-standard events**, or motifs that do not contain the canonical structure seen elsewhere.\n",
    "\n",
    "### (d) Multi-Channel Synchrony\n",
    "\n",
    "Across all clusters, the three channels tend to share:\n",
    "\n",
    "* Similar peak timings\n",
    "* Similar decay phases\n",
    "* Aligned transient features\n",
    "\n",
    "This validates that the motifs are capturing a **coherent multivariate event** rather than unrelated channel-specific fluctuations.\n",
    "\n",
    "### (e) Distinctive Onset Characteristics\n",
    "\n",
    "The main differences between clusters arise from:\n",
    "\n",
    "* Amplitude and sign of the initial transient (first ~150 samples)\n",
    "* Strength of the peak around the motif center (~400–600 samples)\n",
    "* Noise level and decay slope in the final third\n",
    "\n",
    "These distinctions allow the clustering to separate signals not only by shape but also by subtle temporal dynamics.\n",
    "\n",
    "## 4. PCA Visualization\n",
    "\n",
    "PCA 2D and 3D projections show clearly separable cluster groups.\n",
    "Most clusters form well-bounded ellipsoidal clouds, supporting that:\n",
    "\n",
    "* The centroid shapes represent **distinct waveform families**\n",
    "\n",
    "Some overlaps occur between noise-heavy clusters, consistent with the less defined centroid structures observed.\n",
    "\n",
    "## 5. Hierarchical Clustering\n",
    "\n",
    "Hierarchical (Ward) clustering produces a similar structure to KMeans, but with slightly smoother boundaries.\n",
    "Subclusters inside each major group indicate that motifs may have additional **micro-patterns** suitable for sub-clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20fe29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ain427",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
